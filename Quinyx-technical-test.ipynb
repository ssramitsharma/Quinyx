{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "348c43f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "e4b3f0f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eta</th>\n",
       "      <th>ata</th>\n",
       "      <th>atd</th>\n",
       "      <th>vesseldwt</th>\n",
       "      <th>vesseltype</th>\n",
       "      <th>discharge1</th>\n",
       "      <th>load1</th>\n",
       "      <th>discharge2</th>\n",
       "      <th>load2</th>\n",
       "      <th>discharge3</th>\n",
       "      <th>...</th>\n",
       "      <th>load4</th>\n",
       "      <th>stevedorenames</th>\n",
       "      <th>hasnohamis</th>\n",
       "      <th>earliesteta</th>\n",
       "      <th>latesteta</th>\n",
       "      <th>traveltype</th>\n",
       "      <th>previousportid</th>\n",
       "      <th>nextportid</th>\n",
       "      <th>isremarkable</th>\n",
       "      <th>vesselid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-09-19 00:00:00+00</td>\n",
       "      <td>2017-09-19 00:00:00+00</td>\n",
       "      <td>2017-09-22 00:00:00+00</td>\n",
       "      <td>109290.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90173.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Stevedore_104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-09-19 00:00:00+00</td>\n",
       "      <td>2017-09-19 00:00:00+00</td>\n",
       "      <td>ARRIVAL</td>\n",
       "      <td>981.0</td>\n",
       "      <td>731.0</td>\n",
       "      <td>f</td>\n",
       "      <td>2242.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-10-02 00:00:00+00</td>\n",
       "      <td>2017-10-02 00:00:00+00</td>\n",
       "      <td>2017-10-03 00:00:00+00</td>\n",
       "      <td>67170.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Stevedore_109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-10-02 00:00:00+00</td>\n",
       "      <td>2017-10-02 00:00:00+00</td>\n",
       "      <td>ARRIVAL</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>f</td>\n",
       "      <td>5462.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-09-30 00:00:00+00</td>\n",
       "      <td>2017-09-30 00:00:00+00</td>\n",
       "      <td>2017-10-01 00:00:00+00</td>\n",
       "      <td>67737.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Stevedore_57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-09-30 00:00:00+00</td>\n",
       "      <td>2017-09-30 00:00:00+00</td>\n",
       "      <td>ARRIVAL</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>f</td>\n",
       "      <td>5251.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-10-02 00:00:00+00</td>\n",
       "      <td>2017-10-02 00:00:00+00</td>\n",
       "      <td>2017-10-03 00:00:00+00</td>\n",
       "      <td>43600.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Stevedore_57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-10-02 00:00:00+00</td>\n",
       "      <td>2017-10-02 00:00:00+00</td>\n",
       "      <td>ARRIVAL</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>f</td>\n",
       "      <td>5268.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-10-02 00:00:00+00</td>\n",
       "      <td>2017-10-02 00:00:00+00</td>\n",
       "      <td>2017-10-02 00:00:00+00</td>\n",
       "      <td>9231.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Stevedore_98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-10-02 00:00:00+00</td>\n",
       "      <td>2017-10-02 00:00:00+00</td>\n",
       "      <td>ARRIVAL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>f</td>\n",
       "      <td>5504.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8203</th>\n",
       "      <td>2017-11-03 00:00:00+00</td>\n",
       "      <td>2017-11-03 00:00:00+00</td>\n",
       "      <td>2017-11-04 00:00:00+00</td>\n",
       "      <td>9587.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Stevedore_64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-11-02 00:00:00+00</td>\n",
       "      <td>2017-11-03 00:00:00+00</td>\n",
       "      <td>ARRIVAL</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>f</td>\n",
       "      <td>5681.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8204</th>\n",
       "      <td>2017-11-04 00:00:00+00</td>\n",
       "      <td>2017-11-04 00:00:00+00</td>\n",
       "      <td>2017-11-06 00:00:00+00</td>\n",
       "      <td>9654.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Stevedore_110,Stevedore_57,Stevedore_99,Steved...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-11-04 00:00:00+00</td>\n",
       "      <td>2017-11-05 00:00:00+00</td>\n",
       "      <td>SHIFT</td>\n",
       "      <td>391.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>f</td>\n",
       "      <td>4843.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8205</th>\n",
       "      <td>2017-11-08 00:00:00+00</td>\n",
       "      <td>2017-11-07 00:00:00+00</td>\n",
       "      <td>2017-11-11 00:00:00+00</td>\n",
       "      <td>4726.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3051.0</td>\n",
       "      <td>Stevedore_89,Stevedore_79,Stevedore_75,Stevedo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-11-07 00:00:00+00</td>\n",
       "      <td>2017-11-10 00:00:00+00</td>\n",
       "      <td>SHIFT</td>\n",
       "      <td>1043.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>f</td>\n",
       "      <td>3115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8206</th>\n",
       "      <td>2017-11-10 00:00:00+00</td>\n",
       "      <td>2017-11-10 00:00:00+00</td>\n",
       "      <td>2017-11-10 00:00:00+00</td>\n",
       "      <td>13320.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Stevedore_46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-11-10 00:00:00+00</td>\n",
       "      <td>2017-11-10 00:00:00+00</td>\n",
       "      <td>ARRIVAL</td>\n",
       "      <td>54.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>f</td>\n",
       "      <td>4623.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8207</th>\n",
       "      <td>2017-11-10 00:00:00+00</td>\n",
       "      <td>2017-11-08 00:00:00+00</td>\n",
       "      <td>2017-11-10 00:00:00+00</td>\n",
       "      <td>11020.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Stevedore_28,Stevedore_99,Stevedore_57,Stevedo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-11-08 00:00:00+00</td>\n",
       "      <td>2017-11-10 00:00:00+00</td>\n",
       "      <td>SHIFT</td>\n",
       "      <td>1060.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>f</td>\n",
       "      <td>4785.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8208 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         eta                     ata                     atd  \\\n",
       "0     2017-09-19 00:00:00+00  2017-09-19 00:00:00+00  2017-09-22 00:00:00+00   \n",
       "1     2017-10-02 00:00:00+00  2017-10-02 00:00:00+00  2017-10-03 00:00:00+00   \n",
       "2     2017-09-30 00:00:00+00  2017-09-30 00:00:00+00  2017-10-01 00:00:00+00   \n",
       "3     2017-10-02 00:00:00+00  2017-10-02 00:00:00+00  2017-10-03 00:00:00+00   \n",
       "4     2017-10-02 00:00:00+00  2017-10-02 00:00:00+00  2017-10-02 00:00:00+00   \n",
       "...                      ...                     ...                     ...   \n",
       "8203  2017-11-03 00:00:00+00  2017-11-03 00:00:00+00  2017-11-04 00:00:00+00   \n",
       "8204  2017-11-04 00:00:00+00  2017-11-04 00:00:00+00  2017-11-06 00:00:00+00   \n",
       "8205  2017-11-08 00:00:00+00  2017-11-07 00:00:00+00  2017-11-11 00:00:00+00   \n",
       "8206  2017-11-10 00:00:00+00  2017-11-10 00:00:00+00  2017-11-10 00:00:00+00   \n",
       "8207  2017-11-10 00:00:00+00  2017-11-08 00:00:00+00  2017-11-10 00:00:00+00   \n",
       "\n",
       "      vesseldwt  vesseltype  discharge1  load1  discharge2  load2  discharge3  \\\n",
       "0      109290.0         5.0         0.0    0.0         0.0    0.0     90173.0   \n",
       "1       67170.0         3.0         0.0    0.0         0.0    0.0         0.0   \n",
       "2       67737.0         3.0         0.0    0.0         0.0    0.0         0.0   \n",
       "3       43600.0         3.0         0.0    0.0         0.0    0.0         0.0   \n",
       "4        9231.0         3.0         0.0    0.0         0.0    0.0         0.0   \n",
       "...         ...         ...         ...    ...         ...    ...         ...   \n",
       "8203     9587.0         3.0         0.0    0.0         0.0    0.0         0.0   \n",
       "8204     9654.0         3.0         0.0    0.0         0.0    0.0         0.0   \n",
       "8205     4726.0         5.0         0.0    0.0         0.0    0.0         0.0   \n",
       "8206    13320.0         3.0         0.0    0.0         0.0    0.0         0.0   \n",
       "8207    11020.0         3.0         0.0    0.0         0.0    0.0         0.0   \n",
       "\n",
       "      ...   load4                                     stevedorenames  \\\n",
       "0     ...     0.0                                      Stevedore_104   \n",
       "1     ...     0.0                                      Stevedore_109   \n",
       "2     ...     0.0                                       Stevedore_57   \n",
       "3     ...     0.0                                       Stevedore_57   \n",
       "4     ...     0.0                                       Stevedore_98   \n",
       "...   ...     ...                                                ...   \n",
       "8203  ...     0.0                                       Stevedore_64   \n",
       "8204  ...     0.0  Stevedore_110,Stevedore_57,Stevedore_99,Steved...   \n",
       "8205  ...  3051.0  Stevedore_89,Stevedore_79,Stevedore_75,Stevedo...   \n",
       "8206  ...     0.0                                       Stevedore_46   \n",
       "8207  ...     0.0  Stevedore_28,Stevedore_99,Stevedore_57,Stevedo...   \n",
       "\n",
       "      hasnohamis             earliesteta               latesteta traveltype  \\\n",
       "0            NaN  2017-09-19 00:00:00+00  2017-09-19 00:00:00+00    ARRIVAL   \n",
       "1            NaN  2017-10-02 00:00:00+00  2017-10-02 00:00:00+00    ARRIVAL   \n",
       "2            NaN  2017-09-30 00:00:00+00  2017-09-30 00:00:00+00    ARRIVAL   \n",
       "3            NaN  2017-10-02 00:00:00+00  2017-10-02 00:00:00+00    ARRIVAL   \n",
       "4            NaN  2017-10-02 00:00:00+00  2017-10-02 00:00:00+00    ARRIVAL   \n",
       "...          ...                     ...                     ...        ...   \n",
       "8203         NaN  2017-11-02 00:00:00+00  2017-11-03 00:00:00+00    ARRIVAL   \n",
       "8204         NaN  2017-11-04 00:00:00+00  2017-11-05 00:00:00+00      SHIFT   \n",
       "8205         NaN  2017-11-07 00:00:00+00  2017-11-10 00:00:00+00      SHIFT   \n",
       "8206         NaN  2017-11-10 00:00:00+00  2017-11-10 00:00:00+00    ARRIVAL   \n",
       "8207         NaN  2017-11-08 00:00:00+00  2017-11-10 00:00:00+00      SHIFT   \n",
       "\n",
       "     previousportid nextportid  isremarkable  vesselid  \n",
       "0             981.0      731.0             f    2242.0  \n",
       "1              19.0       15.0             f    5462.0  \n",
       "2              19.0       19.0             f    5251.0  \n",
       "3              15.0       18.0             f    5268.0  \n",
       "4              74.0       27.0             f    5504.0  \n",
       "...             ...        ...           ...       ...  \n",
       "8203            5.0       19.0             f    5681.0  \n",
       "8204          391.0      102.0             f    4843.0  \n",
       "8205         1043.0       19.0             f    3115.0  \n",
       "8206           54.0       71.0             f    4623.0  \n",
       "8207         1060.0       14.0             f    4785.0  \n",
       "\n",
       "[8208 rows x 22 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"VesselData.xlsx\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "ef722639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['eta', 'ata', 'atd', 'vesseldwt', 'vesseltype', 'discharge1', 'load1',\n",
       "       'discharge2', 'load2', 'discharge3', 'load3', 'discharge4', 'load4',\n",
       "       'stevedorenames', 'hasnohamis', 'earliesteta', 'latesteta',\n",
       "       'traveltype', 'previousportid', 'nextportid', 'isremarkable',\n",
       "       'vesselid'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c91534b",
   "metadata": {},
   "source": [
    "We need to check the null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "6381b63c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eta                  0\n",
       "ata                  0\n",
       "atd                  0\n",
       "vesseldwt            2\n",
       "vesseltype           0\n",
       "discharge1           0\n",
       "load1                0\n",
       "discharge2           0\n",
       "load2                0\n",
       "discharge3           0\n",
       "load3                0\n",
       "discharge4           0\n",
       "load4                0\n",
       "stevedorenames       2\n",
       "hasnohamis        8208\n",
       "earliesteta          0\n",
       "latesteta            0\n",
       "traveltype           0\n",
       "previousportid       0\n",
       "nextportid           0\n",
       "isremarkable         0\n",
       "vesselid             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de529fde",
   "metadata": {},
   "source": [
    "All the parameters of interest like load1, load2, etc. are devoid of null values hence we can proceed to the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75719ef8",
   "metadata": {},
   "source": [
    "We need to find out the total of load and discharge activity, hence I am summing them up and storing as a column referred to as total. The problem is regression problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "47434913",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Total\"] = df[\"load1\"]+df[\"load2\"]+ df[\"load3\"] + df[\"load4\"] + df[\"discharge1\"]+df[\"discharge2\"]+df[\"discharge3\"]+df[\"discharge4\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b66aecc",
   "metadata": {},
   "source": [
    "The column hasnohamis is full of nan values hence is dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "04af419b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = [\"hasnohamis\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "d289ef22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['eta', 'ata', 'atd', 'vesseldwt', 'vesseltype', 'discharge1', 'load1',\n",
       "       'discharge2', 'load2', 'discharge3', 'load3', 'discharge4', 'load4',\n",
       "       'stevedorenames', 'earliesteta', 'latesteta', 'traveltype',\n",
       "       'previousportid', 'nextportid', 'isremarkable', 'vesselid', 'Total'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d0c6c958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eta               0\n",
       "ata               0\n",
       "atd               0\n",
       "vesseldwt         2\n",
       "vesseltype        0\n",
       "discharge1        0\n",
       "load1             0\n",
       "discharge2        0\n",
       "load2             0\n",
       "discharge3        0\n",
       "load3             0\n",
       "discharge4        0\n",
       "load4             0\n",
       "stevedorenames    2\n",
       "earliesteta       0\n",
       "latesteta         0\n",
       "traveltype        0\n",
       "previousportid    0\n",
       "nextportid        0\n",
       "isremarkable      0\n",
       "vesselid          0\n",
       "Total             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b38058",
   "metadata": {},
   "source": [
    "We replace the nan values with mode of the data, we could also have chosen median or mean. We could have even used linear regression and interplated the data, but since time is short I chose to use mode of the data and replace nan values with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "0fdd4cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stevedorenames'].fillna(df['stevedorenames'].mode()[0], inplace=True)\n",
    "df['vesseldwt'].fillna(df['vesseldwt'].mode()[0], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "039f12d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eta               0\n",
       "ata               0\n",
       "atd               0\n",
       "vesseldwt         0\n",
       "vesseltype        0\n",
       "discharge1        0\n",
       "load1             0\n",
       "discharge2        0\n",
       "load2             0\n",
       "discharge3        0\n",
       "load3             0\n",
       "discharge4        0\n",
       "load4             0\n",
       "stevedorenames    0\n",
       "earliesteta       0\n",
       "latesteta         0\n",
       "traveltype        0\n",
       "previousportid    0\n",
       "nextportid        0\n",
       "isremarkable      0\n",
       "vesselid          0\n",
       "Total             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "c5205dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1374"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df[\"stevedorenames\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0ac947",
   "metadata": {},
   "source": [
    "Now the column stevedorenames could has 1374 types(given the size of the data which is 8000, hence it feels like a good way to convert it to category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "6344f6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "df[\"stevedorenames\"] = le.fit_transform(df[\"stevedorenames\"])\n",
    "df[\"traveltype\"] = le.fit_transform(df[\"traveltype\"])\n",
    "df[\"isremarkable\"] = le.fit_transform(df[\"isremarkable\"])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "fc512d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array(df[\"Total\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "eccb1fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"eta\",\"ata\",\"atd\",\"earliesteta\",\"latesteta\",\"Total\"],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "fb4bcadc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vesseldwt</th>\n",
       "      <th>vesseltype</th>\n",
       "      <th>discharge1</th>\n",
       "      <th>load1</th>\n",
       "      <th>discharge2</th>\n",
       "      <th>load2</th>\n",
       "      <th>discharge3</th>\n",
       "      <th>load3</th>\n",
       "      <th>discharge4</th>\n",
       "      <th>load4</th>\n",
       "      <th>stevedorenames</th>\n",
       "      <th>traveltype</th>\n",
       "      <th>previousportid</th>\n",
       "      <th>nextportid</th>\n",
       "      <th>isremarkable</th>\n",
       "      <th>vesselid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>109290.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90173.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>981.0</td>\n",
       "      <td>731.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2242.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67170.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5462.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67737.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>547</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5251.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43600.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>547</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5268.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9231.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1188</td>\n",
       "      <td>0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5504.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8203</th>\n",
       "      <td>9587.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>729</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5681.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8204</th>\n",
       "      <td>9654.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>154</td>\n",
       "      <td>1</td>\n",
       "      <td>391.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4843.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8205</th>\n",
       "      <td>4726.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3537.0</td>\n",
       "      <td>3051.0</td>\n",
       "      <td>1128</td>\n",
       "      <td>1</td>\n",
       "      <td>1043.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8206</th>\n",
       "      <td>13320.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4623.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8207</th>\n",
       "      <td>11020.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>329</td>\n",
       "      <td>1</td>\n",
       "      <td>1060.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4785.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8208 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      vesseldwt  vesseltype  discharge1  load1  discharge2  load2  discharge3  \\\n",
       "0      109290.0         5.0         0.0    0.0         0.0    0.0     90173.0   \n",
       "1       67170.0         3.0         0.0    0.0         0.0    0.0         0.0   \n",
       "2       67737.0         3.0         0.0    0.0         0.0    0.0         0.0   \n",
       "3       43600.0         3.0         0.0    0.0         0.0    0.0         0.0   \n",
       "4        9231.0         3.0         0.0    0.0         0.0    0.0         0.0   \n",
       "...         ...         ...         ...    ...         ...    ...         ...   \n",
       "8203     9587.0         3.0         0.0    0.0         0.0    0.0         0.0   \n",
       "8204     9654.0         3.0         0.0    0.0         0.0    0.0         0.0   \n",
       "8205     4726.0         5.0         0.0    0.0         0.0    0.0         0.0   \n",
       "8206    13320.0         3.0         0.0    0.0         0.0    0.0         0.0   \n",
       "8207    11020.0         3.0         0.0    0.0         0.0    0.0         0.0   \n",
       "\n",
       "      load3  discharge4   load4  stevedorenames  traveltype  previousportid  \\\n",
       "0       0.0         0.0     0.0              66           0           981.0   \n",
       "1       0.0         0.0     0.0             116           0            19.0   \n",
       "2       0.0         0.0     0.0             547           0            19.0   \n",
       "3       0.0         0.0     0.0             547           0            15.0   \n",
       "4       0.0         0.0     0.0            1188           0            74.0   \n",
       "...     ...         ...     ...             ...         ...             ...   \n",
       "8203    0.0         0.0     0.0             729           0             5.0   \n",
       "8204    0.0         0.0     0.0             154           1           391.0   \n",
       "8205    0.0      3537.0  3051.0            1128           1          1043.0   \n",
       "8206    0.0         0.0     0.0             500           0            54.0   \n",
       "8207    0.0         0.0     0.0             329           1          1060.0   \n",
       "\n",
       "      nextportid  isremarkable  vesselid  \n",
       "0          731.0             0    2242.0  \n",
       "1           15.0             0    5462.0  \n",
       "2           19.0             0    5251.0  \n",
       "3           18.0             0    5268.0  \n",
       "4           27.0             0    5504.0  \n",
       "...          ...           ...       ...  \n",
       "8203        19.0             0    5681.0  \n",
       "8204       102.0             0    4843.0  \n",
       "8205        19.0             0    3115.0  \n",
       "8206        71.0             0    4623.0  \n",
       "8207        14.0             0    4785.0  \n",
       "\n",
       "[8208 rows x 16 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "adbb8933",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "01631a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0929e+05, 5.0000e+00, 0.0000e+00, ..., 7.3100e+02, 0.0000e+00,\n",
       "        2.2420e+03],\n",
       "       [6.7170e+04, 3.0000e+00, 0.0000e+00, ..., 1.5000e+01, 0.0000e+00,\n",
       "        5.4620e+03],\n",
       "       [6.7737e+04, 3.0000e+00, 0.0000e+00, ..., 1.9000e+01, 0.0000e+00,\n",
       "        5.2510e+03],\n",
       "       ...,\n",
       "       [4.7260e+03, 5.0000e+00, 0.0000e+00, ..., 1.9000e+01, 0.0000e+00,\n",
       "        3.1150e+03],\n",
       "       [1.3320e+04, 3.0000e+00, 0.0000e+00, ..., 7.1000e+01, 0.0000e+00,\n",
       "        4.6230e+03],\n",
       "       [1.1020e+04, 3.0000e+00, 0.0000e+00, ..., 1.4000e+01, 0.0000e+00,\n",
       "        4.7850e+03]])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "b9611848",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "f41eea6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "518.8145182724253\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "forest_model = RandomForestRegressor(random_state=1)\n",
    "forest_model.fit(X_train,y_train)\n",
    "melb_preds = forest_model.predict(X_test)\n",
    "print(mean_absolute_error(y_test, melb_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348e7ed1",
   "metadata": {},
   "source": [
    "There are several models that could have been chosen for this task like neural network based approaches(since it is time series data, so We could also have gone for LSTM, GRU), support vector machine. But time is short and I feel random forest is one of the best choice to make. It is one of the most powerful model, it is less prone to overfitting, we need not spend a lot of time for data processing and the results we get are great. Hence I chose this model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5a3f13",
   "metadata": {},
   "source": [
    "\n",
    "How long did you take to complete the test?\n",
    "\n",
    "It took me around 1.5 hour to do it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ede619",
   "metadata": {},
   "source": [
    "Was it easy or challenging? Which parts of the test were easy and which were challenging?\n",
    "\n",
    "The test would have been very easy if I had one more hour. It took time to understand the data, decide as to what should be done. I had to find a solution which is quick. Now, if I had gone for other techniques like neural networks, I would have to spend some time to finalize the number of hidden layers, the network itself, should I use variants of RNN as this is a time series data. Even for svm I had to decide which kernel to use. But random forest is quite robust model and perhabs the best model to go for when the time is short."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2cbb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "What resources did you use to learn how to solve the test (i.e. Google, forums, books)?\n",
    "\n",
    "I used stack overflow a lot, I used it for data processing, I used sklearn documentation for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650d4e2e",
   "metadata": {},
   "source": [
    "Briefly describe the process that you went through to find the solution for the problem.\n",
    "The problem was to predict the total of load & discharge per cargo type. Its a regression problems, hence I summed all the variables like discharge and load to get the total. I dropped some of the columns which I felft were not that relevant like date. I changed some of the variables to categorical data. I divided the data as follows. 67 percent for training and 33 percent for testing used random forest model to make the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8607991e",
   "metadata": {},
   "source": [
    "Are there any other key experiences/notes that you would like us to know in regards to your\n",
    "experience in taking the test?\n",
    "\n",
    "I have never been subjected to timed tests like these. So, it was a new experience for me. I had to always think in a way such that the job gets done on time. So, the quality of work is not good. I would definitely like to try out different ways to solve the problem. I added the discharges and load and made it a parameter, this is what I could think of at this time, I am not sure if my approach is right. I would love to know whether my solution is right or wrong and what could have been done for this problem.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
